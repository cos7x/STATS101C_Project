{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Team</th>\n",
       "      <th>Match Up</th>\n",
       "      <th>Game Date</th>\n",
       "      <th>W/L</th>\n",
       "      <th>MIN</th>\n",
       "      <th>PTS</th>\n",
       "      <th>FGM</th>\n",
       "      <th>FGA</th>\n",
       "      <th>FG%</th>\n",
       "      <th>3PM</th>\n",
       "      <th>...</th>\n",
       "      <th>FT%</th>\n",
       "      <th>OREB</th>\n",
       "      <th>DREB</th>\n",
       "      <th>REB</th>\n",
       "      <th>AST</th>\n",
       "      <th>STL</th>\n",
       "      <th>BLK</th>\n",
       "      <th>TOV</th>\n",
       "      <th>PF</th>\n",
       "      <th>+/-</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GSW</td>\n",
       "      <td>GSW vs. PHX</td>\n",
       "      <td>10/24/2023</td>\n",
       "      <td>L</td>\n",
       "      <td>240</td>\n",
       "      <td>104</td>\n",
       "      <td>36</td>\n",
       "      <td>101</td>\n",
       "      <td>35.6</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>78.6</td>\n",
       "      <td>18</td>\n",
       "      <td>31</td>\n",
       "      <td>49</td>\n",
       "      <td>19</td>\n",
       "      <td>11</td>\n",
       "      <td>6</td>\n",
       "      <td>11</td>\n",
       "      <td>23</td>\n",
       "      <td>-4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PHX</td>\n",
       "      <td>PHX @ GSW</td>\n",
       "      <td>10/24/2023</td>\n",
       "      <td>W</td>\n",
       "      <td>240</td>\n",
       "      <td>108</td>\n",
       "      <td>42</td>\n",
       "      <td>95</td>\n",
       "      <td>44.2</td>\n",
       "      <td>11</td>\n",
       "      <td>...</td>\n",
       "      <td>76.5</td>\n",
       "      <td>17</td>\n",
       "      <td>43</td>\n",
       "      <td>60</td>\n",
       "      <td>23</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>19</td>\n",
       "      <td>22</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LAL</td>\n",
       "      <td>LAL @ DEN</td>\n",
       "      <td>10/24/2023</td>\n",
       "      <td>L</td>\n",
       "      <td>240</td>\n",
       "      <td>107</td>\n",
       "      <td>41</td>\n",
       "      <td>90</td>\n",
       "      <td>45.6</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>75</td>\n",
       "      <td>13</td>\n",
       "      <td>31</td>\n",
       "      <td>44</td>\n",
       "      <td>23</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>18</td>\n",
       "      <td>-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DEN</td>\n",
       "      <td>DEN vs. LAL</td>\n",
       "      <td>10/24/2023</td>\n",
       "      <td>W</td>\n",
       "      <td>240</td>\n",
       "      <td>119</td>\n",
       "      <td>48</td>\n",
       "      <td>91</td>\n",
       "      <td>52.7</td>\n",
       "      <td>14</td>\n",
       "      <td>...</td>\n",
       "      <td>75</td>\n",
       "      <td>9</td>\n",
       "      <td>33</td>\n",
       "      <td>42</td>\n",
       "      <td>29</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>12</td>\n",
       "      <td>15</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MEM</td>\n",
       "      <td>MEM vs. NOP</td>\n",
       "      <td>10/25/2023</td>\n",
       "      <td>L</td>\n",
       "      <td>240</td>\n",
       "      <td>104</td>\n",
       "      <td>38</td>\n",
       "      <td>91</td>\n",
       "      <td>41.8</td>\n",
       "      <td>12</td>\n",
       "      <td>...</td>\n",
       "      <td>80</td>\n",
       "      <td>8</td>\n",
       "      <td>29</td>\n",
       "      <td>37</td>\n",
       "      <td>23</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>13</td>\n",
       "      <td>19</td>\n",
       "      <td>-7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Team     Match Up   Game Date W/L  MIN  PTS  FGM  FGA   FG%  3PM  ...   FT%  \\\n",
       "0  GSW  GSW vs. PHX  10/24/2023   L  240  104   36  101  35.6   10  ...  78.6   \n",
       "1  PHX    PHX @ GSW  10/24/2023   W  240  108   42   95  44.2   11  ...  76.5   \n",
       "2  LAL    LAL @ DEN  10/24/2023   L  240  107   41   90  45.6   10  ...    75   \n",
       "3  DEN  DEN vs. LAL  10/24/2023   W  240  119   48   91  52.7   14  ...    75   \n",
       "4  MEM  MEM vs. NOP  10/25/2023   L  240  104   38   91  41.8   12  ...    80   \n",
       "\n",
       "   OREB  DREB  REB AST  STL  BLK  TOV  PF  +/-  \n",
       "0    18    31   49  19   11    6   11  23   -4  \n",
       "1    17    43   60  23    5    7   19  22    4  \n",
       "2    13    31   44  23    5    4   12  18  -12  \n",
       "3     9    33   42  29    9    6   12  15   12  \n",
       "4     8    29   37  23    8    7   13  19   -7  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load dataset\n",
    "data = pd.read_excel('Dataset.xlsx', engine='openpyxl')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Manipulate Data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Team</th>\n",
       "      <th>Match Up</th>\n",
       "      <th>Game Date</th>\n",
       "      <th>W/L</th>\n",
       "      <th>MIN</th>\n",
       "      <th>PTS</th>\n",
       "      <th>FGM</th>\n",
       "      <th>FGA</th>\n",
       "      <th>FG%</th>\n",
       "      <th>3PM</th>\n",
       "      <th>...</th>\n",
       "      <th>REB</th>\n",
       "      <th>AST</th>\n",
       "      <th>STL</th>\n",
       "      <th>BLK</th>\n",
       "      <th>TOV</th>\n",
       "      <th>PF</th>\n",
       "      <th>+/-</th>\n",
       "      <th>Home Team</th>\n",
       "      <th>Guest Team</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GSW</td>\n",
       "      <td>GSW vs. PHX</td>\n",
       "      <td>2023-10-24</td>\n",
       "      <td>L</td>\n",
       "      <td>240</td>\n",
       "      <td>104</td>\n",
       "      <td>36</td>\n",
       "      <td>101</td>\n",
       "      <td>35.6</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>49</td>\n",
       "      <td>19</td>\n",
       "      <td>11</td>\n",
       "      <td>6</td>\n",
       "      <td>11</td>\n",
       "      <td>23</td>\n",
       "      <td>-4</td>\n",
       "      <td>GSW</td>\n",
       "      <td>PHX</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PHX</td>\n",
       "      <td>PHX @ GSW</td>\n",
       "      <td>2023-10-24</td>\n",
       "      <td>W</td>\n",
       "      <td>240</td>\n",
       "      <td>108</td>\n",
       "      <td>42</td>\n",
       "      <td>95</td>\n",
       "      <td>44.2</td>\n",
       "      <td>11</td>\n",
       "      <td>...</td>\n",
       "      <td>60</td>\n",
       "      <td>23</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>19</td>\n",
       "      <td>22</td>\n",
       "      <td>4</td>\n",
       "      <td>GSW</td>\n",
       "      <td>PHX</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LAL</td>\n",
       "      <td>LAL @ DEN</td>\n",
       "      <td>2023-10-24</td>\n",
       "      <td>L</td>\n",
       "      <td>240</td>\n",
       "      <td>107</td>\n",
       "      <td>41</td>\n",
       "      <td>90</td>\n",
       "      <td>45.6</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>44</td>\n",
       "      <td>23</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>18</td>\n",
       "      <td>-12</td>\n",
       "      <td>DEN</td>\n",
       "      <td>LAL</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DEN</td>\n",
       "      <td>DEN vs. LAL</td>\n",
       "      <td>2023-10-24</td>\n",
       "      <td>W</td>\n",
       "      <td>240</td>\n",
       "      <td>119</td>\n",
       "      <td>48</td>\n",
       "      <td>91</td>\n",
       "      <td>52.7</td>\n",
       "      <td>14</td>\n",
       "      <td>...</td>\n",
       "      <td>42</td>\n",
       "      <td>29</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>12</td>\n",
       "      <td>15</td>\n",
       "      <td>12</td>\n",
       "      <td>DEN</td>\n",
       "      <td>LAL</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MEM</td>\n",
       "      <td>MEM vs. NOP</td>\n",
       "      <td>2023-10-25</td>\n",
       "      <td>L</td>\n",
       "      <td>240</td>\n",
       "      <td>104</td>\n",
       "      <td>38</td>\n",
       "      <td>91</td>\n",
       "      <td>41.8</td>\n",
       "      <td>12</td>\n",
       "      <td>...</td>\n",
       "      <td>37</td>\n",
       "      <td>23</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>13</td>\n",
       "      <td>19</td>\n",
       "      <td>-7</td>\n",
       "      <td>MEM</td>\n",
       "      <td>NOP</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Team     Match Up  Game Date W/L  MIN  PTS  FGM  FGA   FG%  3PM  ...  REB  \\\n",
       "0  GSW  GSW vs. PHX 2023-10-24   L  240  104   36  101  35.6   10  ...   49   \n",
       "1  PHX    PHX @ GSW 2023-10-24   W  240  108   42   95  44.2   11  ...   60   \n",
       "2  LAL    LAL @ DEN 2023-10-24   L  240  107   41   90  45.6   10  ...   44   \n",
       "3  DEN  DEN vs. LAL 2023-10-24   W  240  119   48   91  52.7   14  ...   42   \n",
       "4  MEM  MEM vs. NOP 2023-10-25   L  240  104   38   91  41.8   12  ...   37   \n",
       "\n",
       "   AST  STL  BLK TOV  PF  +/-  Home Team  Guest Team  Label  \n",
       "0   19   11    6  11  23   -4        GSW         PHX      0  \n",
       "1   23    5    7  19  22    4        GSW         PHX      0  \n",
       "2   23    5    4  12  18  -12        DEN         LAL      1  \n",
       "3   29    9    6  12  15   12        DEN         LAL      1  \n",
       "4   23    8    7  13  19   -7        MEM         NOP      0  \n",
       "\n",
       "[5 rows x 27 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert game date to datetime\n",
    "data['Game Date'] = pd.to_datetime(data['Game Date'], format='%m/%d/%Y')\n",
    "\n",
    "# Extract home and guest teams\n",
    "data['Home Team'] = data['Match Up'].apply(lambda x: x.split(' vs. ')[0] if 'vs.' in x else x.split(' @ ')[1])\n",
    "data['Guest Team'] = data['Match Up'].apply(lambda x: x.split(' vs. ')[1] if 'vs.' in x else x.split(' @ ')[0])\n",
    "\n",
    "# Add the correct Label column: 1 if home team won, 0 otherwise\n",
    "data['Label'] = data.apply(\n",
    "    lambda row: 1 if ((row['Team'] == row['Home Team']) and (row['W/L'] == 'W')) \n",
    "                    or ((row['Team'] == row['Guest Team']) and (row['W/L'] == 'L'))\n",
    "                else 0,\n",
    "    axis=1\n",
    ")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculating bias for later adding Home Advatange feature:\n",
    "\n",
    "But don't use in the end because we've already have half of the data to make home advantage's information is in the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculated Bias (Regression): 0.08617886178861786\n"
     ]
    }
   ],
   "source": [
    "# Create a binary feature for home games\n",
    "data['Is_Home'] = data['Match Up'].str.contains(' vs. ').astype(int)\n",
    "\n",
    "# Prepare features and labels\n",
    "X = data[['Is_Home']]  # Home/Away indicator\n",
    "y = (data['W/L'] == 'W').astype(int)  # Convert W/L to binary outcome\n",
    "\n",
    "# Fit a linear regression model\n",
    "model = LinearRegression()\n",
    "model.fit(X, y)\n",
    "\n",
    "# The coefficient of 'Is_Home' represents the home advantage bias\n",
    "bias = model.coef_[0]\n",
    "print(f\"Calculated Bias (Regression): {bias}\")\n",
    "new_bias = 1/21 * bias\n",
    "\n",
    "# Remove the 'Is_Home' column\n",
    "data = data.drop(columns=['Is_Home'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This df below only contains stability features. Here is how this feature were computed:\n",
    "\n",
    "stability score of the feature = mean performance of the feature / variance of the feature\n",
    "\n",
    "stability score of the team = average of the stability score for each features\n",
    "\n",
    "difference in average stability score (what we finally used) = stability score of home team - stability score of guest team"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'output_dataset/Dataset_With_Stability.xlsx'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dataset with new feature: stability score\n",
    "# Initialize the new dataset\n",
    "new_dataset = []\n",
    "\n",
    "# Iterate over each match-up\n",
    "for _, row in data.iterrows():\n",
    "    game_date = row['Game Date']\n",
    "    home_team = row['Home Team']\n",
    "    guest_team = row['Guest Team']\n",
    "    \n",
    "    # Filter games before the current game date for both teams\n",
    "    home_team_games = data[(data['Team'] == home_team) & (data['Game Date'] < game_date)]\n",
    "    guest_team_games = data[(data['Team'] == guest_team) & (data['Game Date'] < game_date)]\n",
    "    \n",
    "    # Calculate W/L rates (win rates) for both teams\n",
    "    home_team_wins = (home_team_games['W/L'] == 'W').sum()\n",
    "    home_team_total = len(home_team_games)\n",
    "    guest_team_wins = (guest_team_games['W/L'] == 'W').sum()\n",
    "    guest_team_total = len(guest_team_games)\n",
    "    \n",
    "    home_win_rate = home_team_wins / home_team_total if home_team_total > 0 else 0\n",
    "    guest_win_rate = guest_team_wins / guest_team_total if guest_team_total > 0 else 0\n",
    "    \n",
    "    # Calculate W/L difference\n",
    "    wl_difference = home_win_rate - guest_win_rate\n",
    "    \n",
    "    # Calculate Stability using mean and variance\n",
    "    if not home_team_games.empty:\n",
    "        home_mean_performance = home_team_games.iloc[:, 5:].mean(numeric_only=True)\n",
    "        home_variance_performance = home_team_games.iloc[:, 5:].var(numeric_only=True)\n",
    "        home_stability = (home_mean_performance / (home_variance_performance + 1e-6)).mean()\n",
    "        home_stability = min(max(home_stability, -100), 100)\n",
    "    else:\n",
    "        home_stability = 0\n",
    "\n",
    "    if not guest_team_games.empty:\n",
    "        guest_mean_performance = guest_team_games.iloc[:, 5:].mean(numeric_only=True)\n",
    "        guest_variance_performance = guest_team_games.iloc[:, 5:].var(numeric_only=True)\n",
    "        guest_stability = (guest_mean_performance / (guest_variance_performance + 1e-6)).mean()\n",
    "        guest_stability = min(max(guest_stability, -100), 100)  # Limit stability within [-100, 100]\n",
    "    else:\n",
    "        guest_stability = 0\n",
    "\n",
    "    # Stability difference\n",
    "    stability = home_stability - guest_stability\n",
    "    \n",
    "    # Prepare the new row\n",
    "    new_row = {\n",
    "        'Game Date': game_date,\n",
    "        'Home Team': home_team,\n",
    "        'Guest Team': guest_team,\n",
    "        'Label': int(row['Label']),  # Ensure Label is directly copied and kept as integer\n",
    "        'W/L Difference': wl_difference,\n",
    "        'Stability': stability\n",
    "    }\n",
    "    \n",
    "    # Add statistics differences (like in the original approach)\n",
    "    home_team_stats = home_team_games.iloc[:, 4:].mean(numeric_only=True)\n",
    "    guest_team_stats = guest_team_games.iloc[:, 4:].mean(numeric_only=True)\n",
    "    \n",
    "    if not home_team_stats.empty and not guest_team_stats.empty:\n",
    "        stats_diff = home_team_stats - guest_team_stats\n",
    "        # Update new_row but ensure no conflict with 'Label'\n",
    "        new_row.update({k: v for k, v in stats_diff.to_dict().items() if k != 'Label'})\n",
    "    \n",
    "    new_dataset.append(new_row)\n",
    "# Convert to DataFrame\n",
    "new_dataset_df_1 = pd.DataFrame(new_dataset)\n",
    "\n",
    "# Save to file for inspection\n",
    "output_file = 'output_dataset/Dataset_With_Stability.xlsx'\n",
    "new_dataset_df_1.to_excel(output_file, index=False)\n",
    "\n",
    "output_file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This fucntion and generated df below contain stability feature, Previous Competitions and Home-Away Win Rate Difference.\n",
    "\n",
    "Home-Away Win Rate Difference: I took the home team's past home win percentage minus the away team's past away win percentage;\n",
    "\n",
    "Previous Competitions: Just like the discreption in guideline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize_match(row):\n",
    "    teams = sorted([row['Home Team'], row['Guest Team']])\n",
    "    standardized_row = {\n",
    "        'Standard Home Team': teams[0],\n",
    "        'Standard Guest Team': teams[1],\n",
    "        'Game Date': row['Game Date'],\n",
    "        'W/L': 'W' if (row['Home Team'] == teams[0] and row['W/L'] == 'W') or\n",
    "                       (row['Guest Team'] == teams[0] and row['W/L'] == 'L') else 'L'\n",
    "    }\n",
    "    return standardized_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'output_dataset/Dataset_with_Stability_and_Previous_Competitions_Corrected.xlsx'"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize the new dataset\n",
    "new_dataset = []\n",
    "\n",
    "# Iterate over each match-up\n",
    "for _, row in data.iterrows():\n",
    "    game_date = row['Game Date']\n",
    "    home_team = row['Home Team']\n",
    "    guest_team = row['Guest Team']\n",
    "    \n",
    "    # Filter games before the current game date for both teams\n",
    "    home_team_games = data[(data['Team'] == home_team) & (data['Game Date'] < game_date)]\n",
    "    guest_team_games = data[(data['Team'] == guest_team) & (data['Game Date'] < game_date)]\n",
    "\n",
    "    # Calculate home team's historical home win rate\n",
    "    home_team_home_games = home_team_games[home_team_games['Match Up'].str.contains('vs.')]\n",
    "    home_team_home_wins = (home_team_home_games['W/L'] == 'W').sum()\n",
    "    home_team_home_total = len(home_team_home_games)\n",
    "    home_team_home_win_rate = home_team_home_wins / home_team_home_total if home_team_home_total > 0 else 0\n",
    "\n",
    "    # Calculate guest team's historical away win rate\n",
    "    guest_team_away_games = guest_team_games[guest_team_games['Match Up'].str.contains('@')]\n",
    "    guest_team_away_wins = (guest_team_away_games['W/L'] == 'W').sum()\n",
    "    guest_team_away_total = len(guest_team_away_games)\n",
    "    guest_team_away_win_rate = guest_team_away_wins / guest_team_away_total if guest_team_away_total > 0 else 0\n",
    "\n",
    "    home_away_win_rate_diff = home_team_home_win_rate - guest_team_away_win_rate\n",
    "\n",
    "    # Filter previous competitions between home and guest teams\n",
    "    previous_matches = data[\n",
    "        ((data['Home Team'] == home_team) & (data['Guest Team'] == guest_team)) |\n",
    "        ((data['Home Team'] == guest_team) & (data['Guest Team'] == home_team))\n",
    "    ]\n",
    "    previous_matches = previous_matches[previous_matches['Game Date'] < game_date]\n",
    "\n",
    "    standardized_matches = previous_matches.apply(standardize_match, axis=1, result_type='expand')\n",
    "\n",
    "    standardized_matches = standardized_matches.drop_duplicates(subset=['Game Date', 'Standard Home Team', 'Standard Guest Team'])\n",
    "\n",
    "    # Calculate Previous Competitions feature (only direct matches between home and guest teams)\n",
    "    previous_competitions_score = 0\n",
    "    for _, match in standardized_matches.iterrows():\n",
    "        if match['Standard Home Team'] == home_team and match['W/L'] == 'W':\n",
    "            previous_competitions_score += 10\n",
    "        elif match['Standard Home Team'] == home_team and match['W/L'] == 'L':\n",
    "            previous_competitions_score -= 10\n",
    "    \n",
    "    # Calculate W/L rates (win rates) for both teams\n",
    "    home_team_wins = (home_team_games['W/L'] == 'W').sum()\n",
    "    home_team_total = len(home_team_games)\n",
    "    guest_team_wins = (guest_team_games['W/L'] == 'W').sum()\n",
    "    guest_team_total = len(guest_team_games)\n",
    "    \n",
    "    home_win_rate = home_team_wins / home_team_total if home_team_total > 0 else 0\n",
    "    guest_win_rate = guest_team_wins / guest_team_total if guest_team_total > 0 else 0\n",
    "    \n",
    "    # Calculate W/L difference\n",
    "    wl_difference = home_win_rate - guest_win_rate\n",
    "    \n",
    "    # Calculate Stability using mean and variance\n",
    "    if not home_team_games.empty:\n",
    "        home_mean_performance = home_team_games.iloc[:, 4:].mean(numeric_only=True)\n",
    "        home_variance_performance = home_team_games.iloc[:, 4:].var(numeric_only=True)\n",
    "        home_stability = (home_mean_performance / (home_variance_performance + 1e-6)).mean()\n",
    "        home_stability = min(max(home_stability, -100), 100)\n",
    "    else:\n",
    "        home_stability = 0\n",
    "\n",
    "    if not guest_team_games.empty:\n",
    "        guest_mean_performance = guest_team_games.iloc[:, 4:].mean(numeric_only=True)\n",
    "        guest_variance_performance = guest_team_games.iloc[:, 4:].var(numeric_only=True)\n",
    "        guest_stability = (guest_mean_performance / (guest_variance_performance + 1e-6)).mean()\n",
    "        guest_stability = min(max(guest_stability, -100), 100)  # Limit stability within [-100, 100]\n",
    "    else:\n",
    "        guest_stability = 0\n",
    "\n",
    "    # Stability difference\n",
    "    stability = home_stability - guest_stability\n",
    "    \n",
    "    # Prepare the new row\n",
    "    new_row = {\n",
    "        'Game Date': game_date,\n",
    "        'Home Team': home_team,\n",
    "        'Guest Team': guest_team,\n",
    "        'Label': int(row['Label']),  # Ensure Label is directly copied and kept as integer\n",
    "        'W/L Difference': wl_difference,\n",
    "        'Stability': stability,\n",
    "        'Previous Competitions': previous_competitions_score,  # Add new feature\n",
    "        'Home-Away Win Rate Difference': home_away_win_rate_diff\n",
    "    }\n",
    "    \n",
    "    # Add statistics differences (like in the original approach)\n",
    "    home_team_stats = home_team_games.iloc[:, 4:].mean(numeric_only=True)\n",
    "    guest_team_stats = guest_team_games.iloc[:, 4:].mean(numeric_only=True)\n",
    "    \n",
    "    if not home_team_stats.empty and not guest_team_stats.empty:\n",
    "        stats_diff = home_team_stats - guest_team_stats\n",
    "        # Update new_row but ensure no conflict with 'Label'\n",
    "        new_row.update({k: v for k, v in stats_diff.to_dict().items() if k != 'Label'})\n",
    "    \n",
    "    new_dataset.append(new_row)\n",
    "\n",
    "# Convert to DataFrame\n",
    "new_dataset_df_1 = pd.DataFrame(new_dataset)\n",
    "\n",
    "# Save to file for inspection\n",
    "output_file = 'output_dataset/Dataset_with_Stability_and_Previous_Competitions_Corrected.xlsx'\n",
    "new_dataset_df_1.to_excel(output_file, index=False)\n",
    "\n",
    "output_file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code below doesn't work. I try to add some weights when I calculating the average statistics, but it failed... You may try to revise it?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Define a weighting function (e.g., exponential decay)\n",
    "def calculate_weight(days_since_match, alpha=0.1):\n",
    "    \"\"\"Calculate weight based on days since match.\"\"\"\n",
    "    return np.exp(-alpha * days_since_match)+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       0.000000\n",
      "1       0.000000\n",
      "2       0.000000\n",
      "3       0.000000\n",
      "4       0.000000\n",
      "          ...   \n",
      "2455   -0.503363\n",
      "2456    1.437285\n",
      "2457    1.352189\n",
      "2458    1.279545\n",
      "2459   -0.221080\n",
      "Name: Stability, Length: 2424, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(new_dataset_df_1['Stability'].dropna())\n",
    "dataset_df_1 = new_dataset_df_1.drop_duplicates().dropna()\n",
    "columns1 = new_dataset_df_1['Stability'].dropna()\n",
    "columns2 = new_dataset_df_1['Previous Competitions'].dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       0\n",
      "1       0\n",
      "2       0\n",
      "3       0\n",
      "4       0\n",
      "       ..\n",
      "2455    0\n",
      "2456    0\n",
      "2457    0\n",
      "2458    0\n",
      "2459    0\n",
      "Name: Previous Competitions, Length: 2460, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(columns2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'output_dataset/Dataset_with_Weights.xlsx'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize the new dataset\n",
    "new_dataset = []\n",
    "\n",
    "# Iterate over each match-up\n",
    "for _, row in data.iterrows():\n",
    "    game_date = row['Game Date']\n",
    "    home_team = row['Home Team']\n",
    "    guest_team = row['Guest Team']\n",
    "    \n",
    "    # Directly preserve the original label (0 or 1)\n",
    "    label = int(row['Label'])\n",
    "\n",
    "    # Filter games before the current game date for both teams\n",
    "    home_team_games = data[(data['Team'] == home_team) & (data['Game Date'] < game_date)].copy()\n",
    "    guest_team_games = data[(data['Team'] == guest_team) & (data['Game Date'] < game_date)].copy()\n",
    "    \n",
    "    # Calculate days since each previous match\n",
    "    home_team_games['Days Since Match'] = (game_date - home_team_games['Game Date']).dt.days\n",
    "    guest_team_games['Days Since Match'] = (game_date - guest_team_games['Game Date']).dt.days\n",
    "\n",
    "    # Apply weighting function\n",
    "    home_team_games['Weight'] = calculate_weight(home_team_games['Days Since Match'])\n",
    "    guest_team_games['Weight'] = calculate_weight(guest_team_games['Days Since Match'])\n",
    "\n",
    "    # Filter numeric columns for weighted calculations\n",
    "    home_numeric_cols = home_team_games.select_dtypes(include=['number']).copy()\n",
    "    guest_numeric_cols = guest_team_games.select_dtypes(include=['number']).copy()\n",
    "\n",
    "    # Ensure weight column exists and is numeric\n",
    "    home_team_games['Weight'] = pd.to_numeric(home_team_games['Weight'], errors='coerce').fillna(0)\n",
    "    guest_team_games['Weight'] = pd.to_numeric(guest_team_games['Weight'], errors='coerce').fillna(0)\n",
    "\n",
    "    # Weighted average calculation for home team\n",
    "    if not home_numeric_cols.empty and not home_team_games.empty:\n",
    "        home_team_stats = (\n",
    "            home_numeric_cols.multiply(home_team_games['Weight'], axis=0).sum()\n",
    "            / home_team_games['Weight'].sum()\n",
    "        )\n",
    "    else:\n",
    "        home_team_stats = pd.Series(0, index=home_numeric_cols.columns)\n",
    "\n",
    "    # Weighted average calculation for guest team\n",
    "    if not guest_numeric_cols.empty and not guest_team_games.empty:\n",
    "        guest_team_stats = (\n",
    "            guest_numeric_cols.multiply(guest_team_games['Weight'], axis=0).sum()\n",
    "            / guest_team_games['Weight'].sum()\n",
    "        )\n",
    "    else:\n",
    "        guest_team_stats = pd.Series(0, index=guest_numeric_cols.columns)\n",
    "\n",
    "    # Calculate weighted W/L rates\n",
    "    home_team_wins = (home_team_games['W/L'] == 'W').astype(float)\n",
    "    home_weighted_win_rate = (home_team_wins * home_team_games['Weight']).sum() / home_team_games['Weight'].sum() if not home_team_games.empty else 0\n",
    "\n",
    "    guest_team_wins = (guest_team_games['W/L'] == 'W').astype(float)\n",
    "    guest_weighted_win_rate = (guest_team_wins * guest_team_games['Weight']).sum() / guest_team_games['Weight'].sum() if not guest_team_games.empty else 0\n",
    "\n",
    "    wl_difference = home_weighted_win_rate - guest_weighted_win_rate\n",
    "\n",
    "    # Calculate Stability using weighted mean and variance\n",
    "    if not home_team_games.empty:\n",
    "        home_stability = (\n",
    "            home_team_games['Weight'] * home_team_games.iloc[:, 4:].var(numeric_only=True)\n",
    "        ).mean()\n",
    "    else:\n",
    "        home_stability = 0\n",
    "\n",
    "    if not guest_team_games.empty:\n",
    "        guest_stability = (\n",
    "            guest_team_games['Weight'] * guest_team_games.iloc[:, 4:].var(numeric_only=True)\n",
    "        ).mean()\n",
    "    else:\n",
    "        guest_stability = 0\n",
    "\n",
    "    stability = home_stability - guest_stability\n",
    "\n",
    "    # Calculate Previous Competitions feature (as before)\n",
    "    previous_matches = data[\n",
    "        ((data['Home Team'] == home_team) & (data['Guest Team'] == guest_team)) |\n",
    "        ((data['Home Team'] == guest_team) & (data['Guest Team'] == home_team))\n",
    "    ]\n",
    "    previous_matches = previous_matches[previous_matches['Game Date'] < game_date]\n",
    "    previous_competitions_score = 0\n",
    "    for _, match in previous_matches.iterrows():\n",
    "        if match['Home Team'] == home_team and match['W/L'] == 'W':\n",
    "            previous_competitions_score += 10\n",
    "        elif match['Home Team'] == home_team and match['W/L'] == 'L':\n",
    "            previous_competitions_score -= 10\n",
    "    \n",
    "    print(previous_competitions_score)\n",
    "\n",
    "    # Prepare the new row\n",
    "    new_row = {\n",
    "        'Game Date': game_date,\n",
    "        'Home Team': home_team,\n",
    "        'Guest Team': guest_team,\n",
    "        'Label': label,  # Use the original label directly\n",
    "        'W/L Difference': wl_difference,\n",
    "        'Stability': stability,\n",
    "        'Previous Competitions': int(previous_competitions_score),  # Ensure Previous Competitions remains integer\n",
    "    }\n",
    "\n",
    "    # Add weighted stats differences to new row\n",
    "    stats_diff = home_team_stats - guest_team_stats\n",
    "    if not stats_diff.empty:\n",
    "    # Ensure we don't overwrite 'Label' and 'Previous Competitions'\n",
    "        stats_diff_filtered = {k: v for k, v in stats_diff.to_dict().items() if k not in ['Label', 'Previous Competitions']}\n",
    "        new_row.update(stats_diff_filtered)\n",
    "\n",
    "    # Append to the dataset\n",
    "    new_dataset.append(new_row)\n",
    "\n",
    "# Convert to DataFrame\n",
    "new_dataset_df_1 = pd.DataFrame(new_dataset)\n",
    "\n",
    "# Save to file for inspection\n",
    "output_file = 'output_dataset/Dataset_with_Weights.xlsx'\n",
    "new_dataset_df_1.to_excel(output_file, index=False)\n",
    "\n",
    "output_file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Always run the below chunck to make sure get a clean dataset (without Na and duplicates)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Game Date</th>\n",
       "      <th>Home Team</th>\n",
       "      <th>Guest Team</th>\n",
       "      <th>Label</th>\n",
       "      <th>W/L Difference</th>\n",
       "      <th>Stability</th>\n",
       "      <th>Previous Competitions</th>\n",
       "      <th>MIN</th>\n",
       "      <th>PTS</th>\n",
       "      <th>FGM</th>\n",
       "      <th>...</th>\n",
       "      <th>DREB</th>\n",
       "      <th>REB</th>\n",
       "      <th>AST</th>\n",
       "      <th>STL</th>\n",
       "      <th>BLK</th>\n",
       "      <th>TOV</th>\n",
       "      <th>PF</th>\n",
       "      <th>+/-</th>\n",
       "      <th>Days Since Match</th>\n",
       "      <th>Weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-10-26</td>\n",
       "      <td>LAL</td>\n",
       "      <td>PHX</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-12.0</td>\n",
       "      <td>-16.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>-7.0</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>-16.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-10-27</td>\n",
       "      <td>SAS</td>\n",
       "      <td>HOU</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>...</td>\n",
       "      <td>12.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-10-27</td>\n",
       "      <td>BOS</td>\n",
       "      <td>MIA</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-10-27</td>\n",
       "      <td>UTA</td>\n",
       "      <td>LAC</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>-6.0</td>\n",
       "      <td>...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>-14.0</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-28.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2023-10-27</td>\n",
       "      <td>SAC</td>\n",
       "      <td>GSW</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.077913</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Game Date Home Team Guest Team  Label  W/L Difference  Stability  \\\n",
       "0 2023-10-26       LAL        PHX      1            -1.0        0.0   \n",
       "2 2023-10-27       SAS        HOU      1             0.0        0.0   \n",
       "3 2023-10-27       BOS        MIA      1             0.0        0.0   \n",
       "4 2023-10-27       UTA        LAC      1            -1.0        0.0   \n",
       "5 2023-10-27       SAC        GSW      0             1.0        0.0   \n",
       "\n",
       "   Previous Competitions  MIN   PTS   FGM  ...  DREB   REB   AST  STL  BLK  \\\n",
       "0                      0  0.0  -1.0  -1.0  ... -12.0 -16.0   0.0  0.0 -3.0   \n",
       "2                      0  0.0  33.0  14.0  ...  12.0  14.0  14.0  2.0  2.0   \n",
       "3                      0  0.0   5.0   0.0  ...   7.0  -2.0  -4.0 -5.0  8.0   \n",
       "4                      0  0.0  -9.0  -6.0  ...   7.0   9.0 -14.0 -5.0 -5.0   \n",
       "5                      0  0.0  26.0  11.0  ...  -1.0  -4.0  10.0 -5.0  2.0   \n",
       "\n",
       "   TOV   PF   +/-  Days Since Match    Weight  \n",
       "0 -7.0 -4.0 -16.0               0.0  0.000000  \n",
       "2  0.0 -1.0  23.0               0.0  0.000000  \n",
       "3  6.0  4.0   3.0               0.0  0.000000  \n",
       "4 -4.0  0.0 -28.0               0.0  0.000000  \n",
       "5  1.0  2.0  20.0              -1.0  0.077913  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove rows with NaN values and drop duplicate rows\n",
    "# dataset_df_1 = new_dataset_df_1.dropna().drop_duplicates()\n",
    "dataset_df_1 = new_dataset_df_1\n",
    "dataset_df_1 = dataset_df_1.iloc[29:]\n",
    "dataset_df_1 = dataset_df_1.drop(index=30).reset_index(drop=True)\n",
    "dataset_df_1 = dataset_df_1.drop_duplicates()\n",
    "dataset_df_1['Stability'] = columns1\n",
    "dataset_df_1['Previous Competitions'] = columns2\n",
    "dataset_df_1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'[1] not found in axis'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[46], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m dataset_df_1 \u001b[38;5;241m=\u001b[39m new_dataset_df_1\n\u001b[0;32m      4\u001b[0m dataset_df_1 \u001b[38;5;241m=\u001b[39m dataset_df_1\u001b[38;5;241m.\u001b[39miloc[\u001b[38;5;241m29\u001b[39m:]\n\u001b[1;32m----> 5\u001b[0m dataset_df_1 \u001b[38;5;241m=\u001b[39m \u001b[43mdataset_df_1\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mreset_index(drop\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m      6\u001b[0m dataset_df_1 \u001b[38;5;241m=\u001b[39m dataset_df_1\u001b[38;5;241m.\u001b[39mdrop_duplicates()\n\u001b[0;32m      7\u001b[0m dataset_df_1[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mStability\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m columns1\n",
      "File \u001b[1;32mc:\\Users\\admin\\anaconda3\\envs\\tf_env\\lib\\site-packages\\pandas\\core\\frame.py:5258\u001b[0m, in \u001b[0;36mDataFrame.drop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   5110\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdrop\u001b[39m(\n\u001b[0;32m   5111\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   5112\u001b[0m     labels: IndexLabel \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   5119\u001b[0m     errors: IgnoreRaise \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   5120\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   5121\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   5122\u001b[0m \u001b[38;5;124;03m    Drop specified labels from rows or columns.\u001b[39;00m\n\u001b[0;32m   5123\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   5256\u001b[0m \u001b[38;5;124;03m            weight  1.0     0.8\u001b[39;00m\n\u001b[0;32m   5257\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 5258\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   5259\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5260\u001b[0m \u001b[43m        \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5261\u001b[0m \u001b[43m        \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5262\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5263\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5264\u001b[0m \u001b[43m        \u001b[49m\u001b[43minplace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minplace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5265\u001b[0m \u001b[43m        \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5266\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\admin\\anaconda3\\envs\\tf_env\\lib\\site-packages\\pandas\\core\\generic.py:4549\u001b[0m, in \u001b[0;36mNDFrame.drop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   4547\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m axis, labels \u001b[38;5;129;01min\u001b[39;00m axes\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m   4548\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m labels \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 4549\u001b[0m         obj \u001b[38;5;241m=\u001b[39m \u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_drop_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4551\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inplace:\n\u001b[0;32m   4552\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_inplace(obj)\n",
      "File \u001b[1;32mc:\\Users\\admin\\anaconda3\\envs\\tf_env\\lib\\site-packages\\pandas\\core\\generic.py:4591\u001b[0m, in \u001b[0;36mNDFrame._drop_axis\u001b[1;34m(self, labels, axis, level, errors, only_slice)\u001b[0m\n\u001b[0;32m   4589\u001b[0m         new_axis \u001b[38;5;241m=\u001b[39m axis\u001b[38;5;241m.\u001b[39mdrop(labels, level\u001b[38;5;241m=\u001b[39mlevel, errors\u001b[38;5;241m=\u001b[39merrors)\n\u001b[0;32m   4590\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 4591\u001b[0m         new_axis \u001b[38;5;241m=\u001b[39m \u001b[43maxis\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4592\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m axis\u001b[38;5;241m.\u001b[39mget_indexer(new_axis)\n\u001b[0;32m   4594\u001b[0m \u001b[38;5;66;03m# Case for non-unique axis\u001b[39;00m\n\u001b[0;32m   4595\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\admin\\anaconda3\\envs\\tf_env\\lib\\site-packages\\pandas\\core\\indexes\\base.py:6699\u001b[0m, in \u001b[0;36mIndex.drop\u001b[1;34m(self, labels, errors)\u001b[0m\n\u001b[0;32m   6697\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mask\u001b[38;5;241m.\u001b[39many():\n\u001b[0;32m   6698\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m errors \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m-> 6699\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlist\u001b[39m(labels[mask])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not found in axis\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   6700\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m indexer[\u001b[38;5;241m~\u001b[39mmask]\n\u001b[0;32m   6701\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdelete(indexer)\n",
      "\u001b[1;31mKeyError\u001b[0m: '[1] not found in axis'"
     ]
    }
   ],
   "source": [
    "# Remove rows with NaN values and drop duplicate rows\n",
    "# dataset_df_1 = new_dataset_df_1.dropna().drop_duplicates()\n",
    "dataset_df_1 = new_dataset_df_1\n",
    "dataset_df_1 = dataset_df_1.iloc[29:]\n",
    "dataset_df_1 = dataset_df_1.drop(index=1).reset_index(drop=True)\n",
    "dataset_df_1 = dataset_df_1.drop_duplicates()\n",
    "dataset_df_1['Stability'] = columns1\n",
    "dataset_df_1['Previous Competitions'] = columns2\n",
    "dataset_df_1.head()\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Step 1: Select columns starting from the 5th column onward\n",
    "features_to_normalize = dataset_df_1.iloc[:, 4:]  # Select all columns from the 5th column onward (0-indexed)\n",
    "\n",
    "# Step 2: Apply Min-Max normalization\n",
    "scaler = MinMaxScaler()\n",
    "normalized_features = scaler.fit_transform(features_to_normalize)\n",
    "\n",
    "# Step 3: Replace the original columns with the normalized ones\n",
    "dataset_df_1.iloc[:, 4:] = normalized_features\n",
    "\n",
    "# Save to file for inspection\n",
    "output_file = 'output_dataset/cleaned_final_dataset_with_features.xlsx'\n",
    "dataset_df_1.to_excel(output_file, index=False)\n",
    "output_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>W/L Difference</th>\n",
       "      <th>Previous Competitions</th>\n",
       "      <th>MIN</th>\n",
       "      <th>PTS</th>\n",
       "      <th>FGM</th>\n",
       "      <th>FGA</th>\n",
       "      <th>FG%</th>\n",
       "      <th>3PM</th>\n",
       "      <th>3PA</th>\n",
       "      <th>3P%</th>\n",
       "      <th>...</th>\n",
       "      <th>DREB</th>\n",
       "      <th>REB</th>\n",
       "      <th>AST</th>\n",
       "      <th>STL</th>\n",
       "      <th>BLK</th>\n",
       "      <th>TOV</th>\n",
       "      <th>PF</th>\n",
       "      <th>+/-</th>\n",
       "      <th>Days Since Match</th>\n",
       "      <th>Weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>595</th>\n",
       "      <td>0.597461</td>\n",
       "      <td>0</td>\n",
       "      <td>0.084775</td>\n",
       "      <td>0.589604</td>\n",
       "      <td>0.569851</td>\n",
       "      <td>0.547862</td>\n",
       "      <td>0.590117</td>\n",
       "      <td>0.673573</td>\n",
       "      <td>0.657608</td>\n",
       "      <td>0.527251</td>\n",
       "      <td>...</td>\n",
       "      <td>0.417901</td>\n",
       "      <td>0.180372</td>\n",
       "      <td>0.446557</td>\n",
       "      <td>0.393120</td>\n",
       "      <td>0.404486</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.403924</td>\n",
       "      <td>0.622708</td>\n",
       "      <td>0.486829</td>\n",
       "      <td>0.498149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>597</th>\n",
       "      <td>0.403925</td>\n",
       "      <td>0</td>\n",
       "      <td>0.746078</td>\n",
       "      <td>0.405397</td>\n",
       "      <td>0.550640</td>\n",
       "      <td>0.826151</td>\n",
       "      <td>0.408239</td>\n",
       "      <td>0.387970</td>\n",
       "      <td>0.531841</td>\n",
       "      <td>0.057293</td>\n",
       "      <td>...</td>\n",
       "      <td>0.625031</td>\n",
       "      <td>0.774333</td>\n",
       "      <td>0.650523</td>\n",
       "      <td>0.474192</td>\n",
       "      <td>0.729047</td>\n",
       "      <td>0.660301</td>\n",
       "      <td>0.481401</td>\n",
       "      <td>0.441260</td>\n",
       "      <td>0.462278</td>\n",
       "      <td>0.544677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>598</th>\n",
       "      <td>0.348062</td>\n",
       "      <td>0</td>\n",
       "      <td>0.637099</td>\n",
       "      <td>0.425914</td>\n",
       "      <td>0.328232</td>\n",
       "      <td>0.455321</td>\n",
       "      <td>0.324600</td>\n",
       "      <td>0.509742</td>\n",
       "      <td>0.522707</td>\n",
       "      <td>0.412075</td>\n",
       "      <td>...</td>\n",
       "      <td>0.548636</td>\n",
       "      <td>0.493831</td>\n",
       "      <td>0.221828</td>\n",
       "      <td>0.650519</td>\n",
       "      <td>0.492034</td>\n",
       "      <td>0.598977</td>\n",
       "      <td>0.678122</td>\n",
       "      <td>0.482406</td>\n",
       "      <td>0.422663</td>\n",
       "      <td>0.606381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>599</th>\n",
       "      <td>0.326012</td>\n",
       "      <td>0</td>\n",
       "      <td>0.403362</td>\n",
       "      <td>0.535457</td>\n",
       "      <td>0.607204</td>\n",
       "      <td>0.482199</td>\n",
       "      <td>0.695127</td>\n",
       "      <td>0.329561</td>\n",
       "      <td>0.181722</td>\n",
       "      <td>0.595868</td>\n",
       "      <td>...</td>\n",
       "      <td>0.582288</td>\n",
       "      <td>0.608803</td>\n",
       "      <td>0.680070</td>\n",
       "      <td>0.280205</td>\n",
       "      <td>0.397625</td>\n",
       "      <td>0.785329</td>\n",
       "      <td>0.668880</td>\n",
       "      <td>0.403685</td>\n",
       "      <td>0.513353</td>\n",
       "      <td>0.489160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>604</th>\n",
       "      <td>0.476502</td>\n",
       "      <td>0</td>\n",
       "      <td>0.753511</td>\n",
       "      <td>0.343028</td>\n",
       "      <td>0.355746</td>\n",
       "      <td>0.455593</td>\n",
       "      <td>0.368094</td>\n",
       "      <td>0.514517</td>\n",
       "      <td>0.602455</td>\n",
       "      <td>0.293503</td>\n",
       "      <td>...</td>\n",
       "      <td>0.398030</td>\n",
       "      <td>0.321524</td>\n",
       "      <td>0.385487</td>\n",
       "      <td>0.631454</td>\n",
       "      <td>0.529323</td>\n",
       "      <td>0.441442</td>\n",
       "      <td>0.495219</td>\n",
       "      <td>0.562413</td>\n",
       "      <td>0.506457</td>\n",
       "      <td>0.512665</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     W/L Difference  Previous Competitions       MIN       PTS       FGM  \\\n",
       "595        0.597461                      0  0.084775  0.589604  0.569851   \n",
       "597        0.403925                      0  0.746078  0.405397  0.550640   \n",
       "598        0.348062                      0  0.637099  0.425914  0.328232   \n",
       "599        0.326012                      0  0.403362  0.535457  0.607204   \n",
       "604        0.476502                      0  0.753511  0.343028  0.355746   \n",
       "\n",
       "          FGA       FG%       3PM       3PA       3P%  ...      DREB  \\\n",
       "595  0.547862  0.590117  0.673573  0.657608  0.527251  ...  0.417901   \n",
       "597  0.826151  0.408239  0.387970  0.531841  0.057293  ...  0.625031   \n",
       "598  0.455321  0.324600  0.509742  0.522707  0.412075  ...  0.548636   \n",
       "599  0.482199  0.695127  0.329561  0.181722  0.595868  ...  0.582288   \n",
       "604  0.455593  0.368094  0.514517  0.602455  0.293503  ...  0.398030   \n",
       "\n",
       "          REB       AST       STL       BLK       TOV        PF       +/-  \\\n",
       "595  0.180372  0.446557  0.393120  0.404486  0.000000  0.403924  0.622708   \n",
       "597  0.774333  0.650523  0.474192  0.729047  0.660301  0.481401  0.441260   \n",
       "598  0.493831  0.221828  0.650519  0.492034  0.598977  0.678122  0.482406   \n",
       "599  0.608803  0.680070  0.280205  0.397625  0.785329  0.668880  0.403685   \n",
       "604  0.321524  0.385487  0.631454  0.529323  0.441442  0.495219  0.562413   \n",
       "\n",
       "     Days Since Match    Weight  \n",
       "595          0.486829  0.498149  \n",
       "597          0.462278  0.544677  \n",
       "598          0.422663  0.606381  \n",
       "599          0.513353  0.489160  \n",
       "604          0.506457  0.512665  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = dataset_df_1.drop(columns=['Label', 'Game Date', 'Home Team', 'Guest Team', 'Stability']) # Features: all columns except 'Label'\n",
    "y = dataset_df_1['Label']  # Labels: the 'Label' column\n",
    "X = X[100:]\n",
    "y = y[100:] # remove first 100 rows to make sure the stability are a lot 0.\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using data standardization and L1 regularization to complete Feature Selection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected features: ['W/L Difference', 'MIN', 'FGA', 'FG%', '3PA', '3P%', 'FTM', 'FTA', 'OREB', 'DREB', 'AST', 'STL', 'TOV', '+/-', 'Days Since Match', 'Weight']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>W/L Difference</th>\n",
       "      <th>MIN</th>\n",
       "      <th>FGA</th>\n",
       "      <th>FG%</th>\n",
       "      <th>3PA</th>\n",
       "      <th>3P%</th>\n",
       "      <th>FTM</th>\n",
       "      <th>FTA</th>\n",
       "      <th>OREB</th>\n",
       "      <th>DREB</th>\n",
       "      <th>AST</th>\n",
       "      <th>STL</th>\n",
       "      <th>TOV</th>\n",
       "      <th>+/-</th>\n",
       "      <th>Days Since Match</th>\n",
       "      <th>Weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>595</th>\n",
       "      <td>0.597461</td>\n",
       "      <td>0.084775</td>\n",
       "      <td>0.547862</td>\n",
       "      <td>0.590117</td>\n",
       "      <td>0.657608</td>\n",
       "      <td>0.527251</td>\n",
       "      <td>0.565053</td>\n",
       "      <td>0.685705</td>\n",
       "      <td>0.271741</td>\n",
       "      <td>0.417901</td>\n",
       "      <td>0.446557</td>\n",
       "      <td>0.393120</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.622708</td>\n",
       "      <td>0.486829</td>\n",
       "      <td>0.498149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>597</th>\n",
       "      <td>0.403925</td>\n",
       "      <td>0.746078</td>\n",
       "      <td>0.826151</td>\n",
       "      <td>0.408239</td>\n",
       "      <td>0.531841</td>\n",
       "      <td>0.057293</td>\n",
       "      <td>0.304923</td>\n",
       "      <td>0.438364</td>\n",
       "      <td>0.876222</td>\n",
       "      <td>0.625031</td>\n",
       "      <td>0.650523</td>\n",
       "      <td>0.474192</td>\n",
       "      <td>0.660301</td>\n",
       "      <td>0.441260</td>\n",
       "      <td>0.462278</td>\n",
       "      <td>0.544677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>598</th>\n",
       "      <td>0.348062</td>\n",
       "      <td>0.637099</td>\n",
       "      <td>0.455321</td>\n",
       "      <td>0.324600</td>\n",
       "      <td>0.522707</td>\n",
       "      <td>0.412075</td>\n",
       "      <td>0.775910</td>\n",
       "      <td>0.714332</td>\n",
       "      <td>0.566643</td>\n",
       "      <td>0.548636</td>\n",
       "      <td>0.221828</td>\n",
       "      <td>0.650519</td>\n",
       "      <td>0.598977</td>\n",
       "      <td>0.482406</td>\n",
       "      <td>0.422663</td>\n",
       "      <td>0.606381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>599</th>\n",
       "      <td>0.326012</td>\n",
       "      <td>0.403362</td>\n",
       "      <td>0.482199</td>\n",
       "      <td>0.695127</td>\n",
       "      <td>0.181722</td>\n",
       "      <td>0.595868</td>\n",
       "      <td>0.594880</td>\n",
       "      <td>0.588698</td>\n",
       "      <td>0.690902</td>\n",
       "      <td>0.582288</td>\n",
       "      <td>0.680070</td>\n",
       "      <td>0.280205</td>\n",
       "      <td>0.785329</td>\n",
       "      <td>0.403685</td>\n",
       "      <td>0.513353</td>\n",
       "      <td>0.489160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>604</th>\n",
       "      <td>0.476502</td>\n",
       "      <td>0.753511</td>\n",
       "      <td>0.455593</td>\n",
       "      <td>0.368094</td>\n",
       "      <td>0.602455</td>\n",
       "      <td>0.293503</td>\n",
       "      <td>0.471495</td>\n",
       "      <td>0.447432</td>\n",
       "      <td>0.493143</td>\n",
       "      <td>0.398030</td>\n",
       "      <td>0.385487</td>\n",
       "      <td>0.631454</td>\n",
       "      <td>0.441442</td>\n",
       "      <td>0.562413</td>\n",
       "      <td>0.506457</td>\n",
       "      <td>0.512665</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     W/L Difference       MIN       FGA       FG%       3PA       3P%  \\\n",
       "595        0.597461  0.084775  0.547862  0.590117  0.657608  0.527251   \n",
       "597        0.403925  0.746078  0.826151  0.408239  0.531841  0.057293   \n",
       "598        0.348062  0.637099  0.455321  0.324600  0.522707  0.412075   \n",
       "599        0.326012  0.403362  0.482199  0.695127  0.181722  0.595868   \n",
       "604        0.476502  0.753511  0.455593  0.368094  0.602455  0.293503   \n",
       "\n",
       "          FTM       FTA      OREB      DREB       AST       STL       TOV  \\\n",
       "595  0.565053  0.685705  0.271741  0.417901  0.446557  0.393120  0.000000   \n",
       "597  0.304923  0.438364  0.876222  0.625031  0.650523  0.474192  0.660301   \n",
       "598  0.775910  0.714332  0.566643  0.548636  0.221828  0.650519  0.598977   \n",
       "599  0.594880  0.588698  0.690902  0.582288  0.680070  0.280205  0.785329   \n",
       "604  0.471495  0.447432  0.493143  0.398030  0.385487  0.631454  0.441442   \n",
       "\n",
       "          +/-  Days Since Match    Weight  \n",
       "595  0.622708          0.486829  0.498149  \n",
       "597  0.441260          0.462278  0.544677  \n",
       "598  0.482406          0.422663  0.606381  \n",
       "599  0.403685          0.513353  0.489160  \n",
       "604  0.562413          0.506457  0.512665  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 1: Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X_standardized = scaler.fit_transform(X)  # Standardize X to have zero mean and unit variance\n",
    "\n",
    "# Step 2: Fit Logistic Regression with L1 regularization for binary model\n",
    "lasso_log_reg = LogisticRegression(penalty='l1', solver='liblinear', C=1.0, random_state=42)  # L1 penalty for feature selection\n",
    "lasso_log_reg.fit(X_standardized, y)\n",
    "\n",
    "# Step 3: Identify selected features\n",
    "selected_features = X.columns[(lasso_log_reg.coef_ != 0).flatten()]  # Keep only features with non-zero coefficients\n",
    "X_selected = X[selected_features]  # Subset original X with selected features\n",
    "\n",
    "print(f\"Selected features: {list(selected_features)}\")\n",
    "#X_selected = X[['Stability', 'Home-Away Win Rate Difference', 'FG%', '3P%', '+/-']]\n",
    "X_selected.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training & Testing using 5-fold cv (including Random Forest, Logistic Regression, Decision Tree, AdaBoost, and QDA):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy of logistic regression is the highest which is about 0.66 for either 1 new feature or 3 new features. So we imporved 0.2 in total..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Accuracy for each fold: [0.6075268817204301, 0.6720430107526881, 0.6182795698924731, 0.6182795698924731, 0.6236559139784946]\n",
      "Random Forest Mean accuracy: 0.63\n",
      "Logistic Regression Accuracy for each fold: [0.6451612903225806, 0.7043010752688172, 0.6451612903225806, 0.6881720430107527, 0.5806451612903226]\n",
      "Logistic Regression Mean accuracy: 0.65\n",
      "Decision Tree Accuracy for each fold: [0.553763440860215, 0.6451612903225806, 0.5967741935483871, 0.5376344086021505, 0.532258064516129]\n",
      "Decision Tree Mean accuracy: 0.57\n",
      "AdaBoost Accuracy for each fold: [0.6505376344086021, 0.6075268817204301, 0.5860215053763441, 0.5698924731182796, 0.6290322580645161]\n",
      "AdaBoost Mean accuracy: 0.61\n",
      "XGBoost Accuracy for each fold: [0.5483870967741935, 0.6827956989247311, 0.6182795698924731, 0.6129032258064516, 0.6021505376344086]\n",
      "XGBoost Mean accuracy: 0.61\n",
      "Kernel SVM Accuracy for each fold: [0.6344086021505376, 0.6881720430107527, 0.6397849462365591, 0.6451612903225806, 0.6129032258064516]\n",
      "Kernel SVM Mean accuracy: 0.64\n",
      "Linear SVM Accuracy for each fold: [0.6397849462365591, 0.6935483870967742, 0.6290322580645161, 0.6989247311827957, 0.5967741935483871]\n",
      "Linear SVM Mean accuracy: 0.65\n"
     ]
    }
   ],
   "source": [
    "# Ensure data is shuffled before splitting\n",
    "X_shuffled, y_shuffled = shuffle(X_selected, y, random_state=0)\n",
    "\n",
    "# Initialize models\n",
    "models = {\n",
    "    'Random Forest': RandomForestClassifier(random_state=0),\n",
    "    'Logistic Regression': LogisticRegression(random_state=0, max_iter=1000),\n",
    "    'Decision Tree': DecisionTreeClassifier(random_state=0),\n",
    "    'AdaBoost': AdaBoostClassifier(random_state=0),\n",
    "    #'QDA': QuadraticDiscriminantAnalysis(),\n",
    "    'XGBoost': XGBClassifier(eval_metric='logloss', random_state=0),\n",
    "    'Kernel SVM': SVC(kernel='rbf', random_state=0),\n",
    "    'Linear SVM': SVC(kernel='linear', random_state=0)  # Add kernel SVM\n",
    "}\n",
    "\n",
    "# Initialize K-Fold with shuffle\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=0)\n",
    "\n",
    "# Store accuracies for each model\n",
    "model_accuracies = {model_name: [] for model_name in models}\n",
    "\n",
    "for train_index, test_index in kf.split(X_shuffled):\n",
    "    # Split the data into training and testing sets\n",
    "    X_train, X_test = X_shuffled.iloc[train_index], X_shuffled.iloc[test_index]\n",
    "    y_train, y_test = y_shuffled.iloc[train_index], y_shuffled.iloc[test_index]\n",
    "    \n",
    "    for model_name, model in models.items():\n",
    "        # Fit the model\n",
    "        model.fit(X_train, y_train)\n",
    "        \n",
    "        # Predict on the test set\n",
    "        y_pred = model.predict(X_test)\n",
    "        \n",
    "        # Calculate accuracy\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        model_accuracies[model_name].append(accuracy)\n",
    "\n",
    "# Print results\n",
    "for model_name, accuracies in model_accuracies.items():\n",
    "    print(f\"{model_name} Accuracy for each fold: {accuracies}\")\n",
    "    print(f\"{model_name} Mean accuracy: {sum(accuracies) / len(accuracies):.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code below is about a neural network without using k-fold.\n",
    "\n",
    "The accuracy of data with only stability is about 0.66.\n",
    "\n",
    "The accuracy of data with stability, previous competitionm and Home-Away Win Rate Difference is also about 0.66."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 0.6696 - accuracy: 0.5712 - val_loss: 0.6619 - val_accuracy: 0.6030\n",
      "Epoch 2/20\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 0.6244 - accuracy: 0.6537 - val_loss: 0.6450 - val_accuracy: 0.6303\n",
      "Epoch 3/20\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 0.6196 - accuracy: 0.6552 - val_loss: 0.6429 - val_accuracy: 0.6273\n",
      "Epoch 4/20\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 0.6026 - accuracy: 0.6732 - val_loss: 0.6393 - val_accuracy: 0.6303\n",
      "Epoch 5/20\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 0.6063 - accuracy: 0.6537 - val_loss: 0.6374 - val_accuracy: 0.6394\n",
      "Epoch 6/20\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 0.6085 - accuracy: 0.6657 - val_loss: 0.6379 - val_accuracy: 0.6333\n",
      "Epoch 7/20\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 0.5942 - accuracy: 0.6777 - val_loss: 0.6360 - val_accuracy: 0.6333\n",
      "Epoch 8/20\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 0.5858 - accuracy: 0.6792 - val_loss: 0.6371 - val_accuracy: 0.6394\n",
      "Epoch 9/20\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 0.5775 - accuracy: 0.6777 - val_loss: 0.6386 - val_accuracy: 0.6394\n",
      "Epoch 10/20\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 0.5815 - accuracy: 0.6852 - val_loss: 0.6426 - val_accuracy: 0.6424\n",
      "Epoch 11/20\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 0.5971 - accuracy: 0.6582 - val_loss: 0.6399 - val_accuracy: 0.6424\n",
      "Epoch 12/20\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 0.5789 - accuracy: 0.6777 - val_loss: 0.6422 - val_accuracy: 0.6455\n",
      "Epoch 13/20\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 0.5849 - accuracy: 0.6822 - val_loss: 0.6428 - val_accuracy: 0.6303\n",
      "Epoch 14/20\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 0.5876 - accuracy: 0.6672 - val_loss: 0.6418 - val_accuracy: 0.6485\n",
      "Epoch 15/20\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 0.5833 - accuracy: 0.6912 - val_loss: 0.6438 - val_accuracy: 0.6394\n",
      "Epoch 16/20\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.5710 - accuracy: 0.6912 - val_loss: 0.6457 - val_accuracy: 0.6515\n",
      "Epoch 17/20\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 0.5733 - accuracy: 0.6702 - val_loss: 0.6474 - val_accuracy: 0.6455\n",
      "Epoch 18/20\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.5742 - accuracy: 0.7016 - val_loss: 0.6465 - val_accuracy: 0.6515\n",
      "Epoch 19/20\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.5582 - accuracy: 0.7016 - val_loss: 0.6502 - val_accuracy: 0.6515\n",
      "Epoch 20/20\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.5590 - accuracy: 0.7016 - val_loss: 0.6510 - val_accuracy: 0.6455\n",
      "Neural Network Test Accuracy: 0.65\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_selected, y, test_size=0.3, random_state=8)\n",
    "\n",
    "X_train = X_train[100:]\n",
    "y_train = y_train[100:]\n",
    "\n",
    "# Step 2: Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Step 3: Build the neural network model\n",
    "model = Sequential([\n",
    "    Dense(64, input_dim=X_train.shape[1], activation='relu'),  # First hidden layer\n",
    "    Dropout(0.3),  # Dropout for regularization\n",
    "    Dense(32, activation='relu'),  # Second hidden layer\n",
    "    Dense(1, activation='sigmoid')  # Output layer (binary classification)\n",
    "])\n",
    "\n",
    "# Step 4: Compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Step 5: Train the model\n",
    "history = model.fit(X_train, y_train, epochs=20, batch_size=32, validation_data=(X_test, y_test), verbose=1)\n",
    "\n",
    "# Step 6: Evaluate the model on the test set\n",
    "y_pred = (model.predict(X_test) > 0.5).astype(int)  # Convert probabilities to binary predictions\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Neural Network Test Accuracy: {accuracy:.2f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
